# Day 16: Red Teaming GenAIâ€”Practical Checklist for Safer AI

## Overview
Day 16 covers red teaming: stress-testing GenAI systems to uncover vulnerabilities and unsafe behaviors.

## What You'll Learn
- What red teaming is and why it matters
- How to use a checklist to test LLM outputs
- How to spot prompt injection and harmful content

## Demo
The Python script `red_team_checklist.py` demonstrates:
- Running a red teaming checklist of prompts
- Reviewing LLM outputs for unsafe or unexpected behavior

## How to Run
1. Install dependencies:
   ```bash
   pip install openai
2. Add your OpenAI API key to the script.
3. Run the script - python code/red_team_checklist.py
