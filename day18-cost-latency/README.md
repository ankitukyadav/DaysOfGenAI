# Day 18: Cost, Latency, Caching & Throughputâ€”GenAI in the Real World

## Overview
Day 18 covers the trade-offs of cost, latency, caching, and throughput in GenAI deployments.

## What You'll Learn
- How to reduce cost and latency with caching
- How to balance throughput and user experience
- Why these trade-offs matter in production

## Demo
The Python script `caching_demo.py` demonstrates:
- Using an in-memory cache for LLM responses
- Reducing repeated API calls and latency

## How to Run
1. Install dependencies:
   ```bash
   pip install openai
