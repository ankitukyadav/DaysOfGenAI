# Day 27: Adapters & LoRAâ€”Parameter-Efficient Tuning for LLMs

## Overview
Day 27 explores adapters and LoRA for efficient LLM fine-tuning.

## What You'll Learn
- How adapters and LoRA work for LLMs
- Why parameter-efficient tuning matters
- How to apply LoRA with HuggingFace and peft

## Demo
The Python script `lora_finetune.py` demonstrates:
- Applying LoRA to a BERT model for sentiment analysis

## How to Run
1. Install dependencies:
   ```bash
   pip install transformers datasets torch peft
2. Run Script
    python code/lora_finetune.py
